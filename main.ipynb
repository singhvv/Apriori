{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the database sizes\n",
    "D1K_SIZE = 5\n",
    "D10K_SIZE = 10000\n",
    "D50K_SIZE = 50000\n",
    "D100K_SIZE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the database file names\n",
    "D1K_FILE = \"D1K.txt\"\n",
    "D10K_FILE = \"D10K.txt\"\n",
    "D50K_FILE = \"D50K.txt\"\n",
    "D100K_FILE = \"D100K.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function to generate a random transaction\n",
    "def gen_transaction(num):\n",
    "    transaction = []\n",
    "    for i in range(num):\n",
    "        # Generate a random item index between 0 and 99\n",
    "        item_index = random.randint(0, 99)\n",
    "        transaction.append(item_index)\n",
    "    return transaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function to generate a transactional database\n",
    "def gen_database(file_name, db_size):\n",
    "    with open(file_name, 'w') as db_file:\n",
    "        for i in range(db_size):\n",
    "            # Generate a random transaction size between 5 and 15\n",
    "            transaction_size = random.randint(5, 15)\n",
    "            # Generate a random transaction and write it to the file\n",
    "            transaction = gen_transaction(transaction_size)\n",
    "            db_file.write(\" \".join([f\"i{item}\" for item in transaction]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate the four transactional databases\n",
    "gen_database(D1K_FILE, D1K_SIZE)\n",
    "# gen_database(D10K_FILE, D10K_SIZE)\n",
    "# gen_database(D50K_FILE, D50K_SIZE)\n",
    "# gen_database(D100K_FILE, D100K_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Define a function to read a transactional database from a file\n",
    "def read_database(file_name):\n",
    "    with open(file_name, 'r') as db_file:\n",
    "        transactions = [set(line.strip().split()) for line in db_file]\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Apriori algorithm function\n",
    "def apriori(db, min_support):\n",
    "    # Step 1: Find frequent 1-itemsets\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in db:\n",
    "        for item in transaction:\n",
    "            item_counts[item] += 1\n",
    "    num_transactions = len(db)\n",
    "    freq_k_itemsets = {frozenset([item]): count / num_transactions for item, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "\n",
    "    frequent_itemsets = freq_k_itemsets\n",
    "    # Step 2: Generate k-itemsets and find frequent ones until no more frequent itemsets are found\n",
    "    k = 1\n",
    "    while len(freq_k_itemsets) > 0:\n",
    "        k += 1\n",
    "\n",
    "        # Generate candidate k-itemsets from frequent (k-1)-itemsets\n",
    "        candidate_itemsets = set([itemset1.union(itemset2) for itemset1 in frequent_itemsets for itemset2 in frequent_itemsets if len(itemset1.union(itemset2)) == k])\n",
    "        # Count the support of each candidate itemset\n",
    "        item_counts = defaultdict(int)\n",
    "        for transaction in db:\n",
    "            for candidate_itemset in candidate_itemsets:\n",
    "                if candidate_itemset.issubset(transaction):\n",
    "                    item_counts[candidate_itemset] += 1\n",
    "        # Find frequent k-itemsets\n",
    "        freq_k_itemsets = {itemset: count / num_transactions for itemset, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "        frequent_itemsets.update(freq_k_itemsets)\n",
    "\n",
    "        return frequent_itemsets, k\n",
    "\n",
    "\n",
    "# db = read_database('D1K.txt')\n",
    "# frequent_itemsets = apriori(db, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to write frequent itemsets to a file\n",
    "def write_frequent_itemsets(file_name, frequent_itemsets):\n",
    "    with open(file_name, 'w') as freq_file:\n",
    "        for itemset, support in frequent_itemsets.items():\n",
    "            if len(itemset) == 1: continue\n",
    "            freq_file.write(\"{\" + \", \".join([f\"{item}\" for item in itemset]) + \"} \" + f\"{support:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the main function to run the Apriori algorithm on a database and save frequent itemsets to a file\n",
    "def main(db_file_name, min_support, apriori_fn=apriori):\n",
    "    print(\"1\", db_file_name)\n",
    "    db = read_database(db_file_name)\n",
    "    frequent_itemsets, k = apriori_fn(db, min_support)\n",
    "    print(f'k = {k-1}')\n",
    "    freq_file_name = db_file_name.replace(\".txt\", f\"_AprioriAlgo_{int(min_support*100)}.freq\")\n",
    "    write_frequent_itemsets(freq_file_name, frequent_itemsets)\n",
    "    print(f\"Number of transactions found: {len(frequent_itemsets)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D1K.txt\n",
      "k = 1\n",
      "Number of transactions found: 25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the program using the first database with min_support = 1%\n",
    "main(\"D1K.txt\", 0.21)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Idea 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Apriori algorithm function\n",
    "def apriori_idea1(db, min_support):\n",
    "    # Step 1: Find frequent 1-itemsets\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in db:\n",
    "        for item in transaction:\n",
    "            item_counts[item] += 1\n",
    "    num_transactions = len(db)\n",
    "    freq_k_itemsets_all = {frozenset([item]): count / num_transactions for item, count in item_counts.items()}\n",
    "    freq_k_itemsets = {frozenset([item]): count / num_transactions for item, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "    db_all_freq1 = []  # db with all transactions with freq itemset\n",
    "    for transaction in db:\n",
    "        satisfy_supp = False\n",
    "        for it in transaction:\n",
    "            if freq_k_itemsets_all[frozenset({it})] >= min_support:\n",
    "                satisfy_supp = True\n",
    "        if satisfy_supp:\n",
    "            db_all_freq1.append(transaction)\n",
    "\n",
    "    frequent_itemsets = freq_k_itemsets\n",
    "    # Step 2: Generate k-itemsets and find frequent ones until no more frequent itemsets are found\n",
    "    k = 1\n",
    "    while len(freq_k_itemsets) > 0:\n",
    "        k += 1\n",
    "\n",
    "        # Generate candidate k-itemsets from frequent (k-1)-itemsets\n",
    "        candidate_itemsets = set([itemset1.union(itemset2) for itemset1 in frequent_itemsets for itemset2 in frequent_itemsets if len(itemset1.union(itemset2)) == k])\n",
    "        # Count the support of each candidate itemset\n",
    "        item_counts = defaultdict(int)\n",
    "        for transaction in db_all_freq1:\n",
    "            for candidate_itemset in candidate_itemsets:\n",
    "                if candidate_itemset.issubset(transaction):\n",
    "                    item_counts[candidate_itemset] += 1\n",
    "        # Find frequent k-itemsets\n",
    "        freq_k_itemsets = {itemset: count / num_transactions for itemset, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "        frequent_itemsets.update(freq_k_itemsets)\n",
    "\n",
    "        return frequent_itemsets, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D1K.txt\n",
      "k = 1\n",
      "Number of transactions found: 25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main('D1K.txt', .21, apriori_fn=apriori_idea1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
