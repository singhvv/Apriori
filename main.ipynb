{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the database sizes\n",
    "D1K_SIZE = 1000\n",
    "D10K_SIZE = 10000\n",
    "D50K_SIZE = 50000\n",
    "D100K_SIZE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the database file names\n",
    "D1K_FILE = \"D1K.txt\"\n",
    "D10K_FILE = \"D10K.txt\"\n",
    "D50K_FILE = \"D50K.txt\"\n",
    "D100K_FILE = \"D100K.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function to generate a random transaction\n",
    "def gen_transaction(num):\n",
    "    transaction = []\n",
    "    for i in range(num):\n",
    "        # Generate a random item index between 0 and 99\n",
    "        item_index = random.randint(0, 99)\n",
    "        transaction.append(item_index)\n",
    "    return transaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function to generate a transactional database\n",
    "def gen_database(file_name, db_size):\n",
    "    with open(file_name, 'w') as db_file:\n",
    "        for i in range(db_size):\n",
    "            # Generate a random transaction size between 5 and 15\n",
    "            transaction_size = random.randint(5, 15)\n",
    "            # Generate a random transaction and write it to the file\n",
    "            transaction = gen_transaction(transaction_size)\n",
    "            db_file.write(\" \".join([f\"i{item}\" for item in transaction]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate the four transactional databases\n",
    "gen_database(D1K_FILE, D1K_SIZE)\n",
    "gen_database(D10K_FILE, D10K_SIZE)\n",
    "gen_database(D50K_FILE, D50K_SIZE)\n",
    "gen_database(D100K_FILE, D100K_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Define a function to read a transactional database from a file\n",
    "def read_database(file_name):\n",
    "    with open(file_name, 'r') as db_file:\n",
    "        transactions = [set(line.strip().split()) for line in db_file]\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Apriori algorithm function\n",
    "def apriori(db, min_support):\n",
    "    # Step 1: Find frequent 1-itemsets\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in db:\n",
    "        for item in transaction:\n",
    "            item_counts[item] += 1\n",
    "    num_transactions = len(db)\n",
    "    freq_k_itemsets = {frozenset([item]): count / num_transactions for item, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "    frequent_itemsets = freq_k_itemsets\n",
    "    # Step 2: Generate k-itemsets and find frequent ones until no more frequent itemsets are found\n",
    "    k = 1\n",
    "    while len(freq_k_itemsets) > 0:\n",
    "        k += 1\n",
    "        # Generate candidate k-itemsets from frequent (k-1)-itemsets\n",
    "        candidate_itemsets = set([itemset1.union(itemset2) for itemset1 in frequent_itemsets for itemset2 in frequent_itemsets if len(itemset1.union(itemset2)) == k])\n",
    "        # Count the support of each candidate itemset\n",
    "        item_counts = defaultdict(int)\n",
    "        for transaction in db:\n",
    "            for candidate_itemset in candidate_itemsets:\n",
    "                if candidate_itemset.issubset(transaction):\n",
    "                    item_counts[candidate_itemset] += 1\n",
    "        # Find frequent k-itemsets\n",
    "        freq_k_itemsets = {itemset: count / num_transactions for itemset, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "        frequent_itemsets.update(freq_k_itemsets)\n",
    "    return frequent_itemsets, k\n",
    "# db = read_database('D1K.txt')\n",
    "# frequent_itemsets = apriori(db, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to write frequent itemsets to a file\n",
    "def write_frequent_itemsets(file_name, frequent_itemsets):\n",
    "    with open(file_name, 'w') as freq_file:\n",
    "        for itemset, support in frequent_itemsets.items():\n",
    "            freq_file.write(\"{\" + \", \".join([f\"i{item}\" for item in itemset]) + \"} \" + f\"{support:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the main function to run the Apriori algorithm on a database and save frequent itemsets to a file\n",
    "# def main(db_file_name, min_support):\n",
    "#     print(\"1\", db_file_name)\n",
    "#     db = read_database(db_file_name)\n",
    "#     frequent_itemsets, k = apriori(db, min_support)\n",
    "#     print(f'k = {k-1}')\n",
    "#     freq_file_name = db_file_name.replace(\".txt\", f\"_Apriori_{int(min_support*100)}.freq\")\n",
    "#     write_frequent_itemsets(freq_file_name, frequent_itemsets)\n",
    "#     print(f\"Number of scans: {len(frequent_itemsets)}\\n\")\n",
    "\n",
    "\n",
    "# Define the main function to run the Apriori algorithm on a database and save frequent itemsets to a file\n",
    "def main(db_file_name, min_support, apriori_fn=apriori):\n",
    "    print(\"1\", db_file_name)\n",
    "    db = read_database(db_file_name)\n",
    "    frequent_itemsets, k = apriori_fn(db, min_support)\n",
    "    print(f'k = {k-1}')\n",
    "    freq_file_name = db_file_name.replace(\".txt\", f\"_AprioriAlgo_{apriori_fn.__name__}_{int(min_support*100)}.freq\")\n",
    "    write_frequent_itemsets(freq_file_name, frequent_itemsets)\n",
    "    print(f\"Number of itemsets found: {len(frequent_itemsets)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D1K.txt\n",
      "k = 2\n",
      "Number of itemsets found: 2136\n",
      "\n",
      "1 D10K.txt\n",
      "k = 2\n",
      "Number of itemsets found: 885\n",
      "\n",
      "1 D50K.txt\n",
      "k = 2\n",
      "Number of itemsets found: 151\n",
      "\n",
      "1 D100K.txt\n",
      "k = 2\n",
      "Number of itemsets found: 103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the program using the first two databases with min_support = 1%\n",
    "main(\"D1K.txt\", 0.01)\n",
    "main(\"D10K.txt\", 0.01)\n",
    "main(\"D50K.txt\", 0.01)\n",
    "main(\"D100K.txt\", 0.01)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D1K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 100\n",
      "\n",
      "1 D10K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 100\n",
      "\n",
      "1 D50K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 100\n",
      "\n",
      "1 D100K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Apriori algorithm using the four databases with min_support = 5%\n",
    "main(\"D1K.txt\", 0.05)\n",
    "main(\"D10K.txt\", 0.05)\n",
    "main(\"D50K.txt\", 0.05)\n",
    "main(\"D100K.txt\", 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D1K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 96\n",
      "\n",
      "1 D10K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 100\n",
      "\n",
      "1 D50K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 100\n",
      "\n",
      "1 D100K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Apriori algorithm using the four databases with min_support = 8%\n",
    "main(\"D1K.txt\", 0.08)\n",
    "main(\"D10K.txt\", 0.08)\n",
    "main(\"D50K.txt\", 0.08)\n",
    "main(\"D100K.txt\", 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D1K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 34\n",
      "\n",
      "1 D10K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 2\n",
      "\n",
      "1 D50K.txt\n",
      "k = 0\n",
      "Number of itemsets found: 0\n",
      "\n",
      "1 D100K.txt\n",
      "k = 0\n",
      "Number of itemsets found: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Apriori algorithm using the four databases with min_support = 10%\n",
    "main(\"D1K.txt\", 0.1)\n",
    "main(\"D10K.txt\", 0.1)\n",
    "main(\"D50K.txt\", 0.1)\n",
    "main(\"D100K.txt\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D1K.txt\n",
      "k = 0\n",
      "Number of itemsets found: 0\n",
      "\n",
      "1 D10K.txt\n",
      "k = 0\n",
      "Number of itemsets found: 0\n",
      "\n",
      "1 D50K.txt\n",
      "k = 0\n",
      "Number of itemsets found: 0\n",
      "\n",
      "1 D100K.txt\n",
      "k = 0\n",
      "Number of itemsets found: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Apriori algorithm using the four databases with min_support = 15%\n",
    "main(\"D1K.txt\", 0.15)\n",
    "main(\"D10K.txt\", 0.15)\n",
    "main(\"D50K.txt\", 0.15)\n",
    "main(\"D100K.txt\", 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D50K.txt\n",
      "k = 1\n",
      "Number of itemsets found: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main(\"D50K.txt\", 0.097)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\vps12\\Documents\\Assignments\\4_Spring23\\4310\\Project\\git\\Apriori\n",
      "Output file path: c:\\Users\\vps12\\Documents\\Assignments\\4_Spring23\\4310\\Project\\git\\Apriori\\D1K.txt_Apriori_1.freq\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "# Construct the output file path\n",
    "output_file_path = f\"D1K.txt_Apriori_1.freq\"\n",
    "output_file_path = os.path.join(cwd, output_file_path)\n",
    "print(\"Output file path:\", output_file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Apriori algorithm function\n",
    "def apriori_idea1(db, min_support):\n",
    "    # Step 1: Find frequent 1-itemsets\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in db:\n",
    "        for item in transaction:\n",
    "            item_counts[item] += 1\n",
    "    num_transactions = len(db)\n",
    "    freq_k_itemsets_all = {frozenset([item]): count / num_transactions for item, count in item_counts.items()}\n",
    "    freq_k_itemsets = {frozenset([item]): count / num_transactions for item, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "    db_all_freq1 = []  # db with all transactions with freq itemset\n",
    "    for transaction in db:\n",
    "        satisfy_supp = False\n",
    "        for it in transaction:\n",
    "            if freq_k_itemsets_all[frozenset({it})] >= min_support:\n",
    "                satisfy_supp = True\n",
    "        if satisfy_supp:\n",
    "            db_all_freq1.append(transaction)\n",
    "            \n",
    "    \n",
    "    ########\n",
    "    print(len(db), len(db_all_freq1))\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in db_all_freq1:\n",
    "        for item in transaction:\n",
    "            item_counts[item] += 1\n",
    "    num_transactions = len(db_all_freq1)\n",
    "    freq_k_itemsets = {frozenset([item]): count / num_transactions for item, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "    ########\n",
    "\n",
    "    frequent_itemsets = freq_k_itemsets\n",
    "    # Step 2: Generate k-itemsets and find frequent ones until no more frequent itemsets are found\n",
    "    k = 1\n",
    "    while len(freq_k_itemsets) > 0:\n",
    "        k += 1\n",
    "\n",
    "        # Generate candidate k-itemsets from frequent (k-1)-itemsets\n",
    "        candidate_itemsets = set([itemset1.union(itemset2) for itemset1 in frequent_itemsets for itemset2 in frequent_itemsets if len(itemset1.union(itemset2)) == k])\n",
    "        # Count the support of each candidate itemset\n",
    "        item_counts = defaultdict(int)\n",
    "        for transaction in db_all_freq1:\n",
    "            for candidate_itemset in candidate_itemsets:\n",
    "                if candidate_itemset.issubset(transaction):\n",
    "                    item_counts[candidate_itemset] += 1\n",
    "        # Find frequent k-itemsets\n",
    "        freq_k_itemsets = {itemset: count / num_transactions for itemset, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "        frequent_itemsets.update(freq_k_itemsets)\n",
    "\n",
    "    return frequent_itemsets, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D1K.txt\n",
      "1000 981\n",
      "k = 1\n",
      "Number of itemsets found: 36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Idea 1 using the four databases with min_support = 1%\n",
    "a1 = main('D1K.txt', 0.01, apriori_fn=apriori_idea1)\n",
    "b1 = main('D10K.txt', 0.01, apriori_fn=apriori_idea1)\n",
    "c1 = main('D50K.txt', 0.01, apriori_fn=apriori_idea1)\n",
    "d1 = main('D100K.txt', 0.01, apriori_fn=apriori_idea1)\n",
    "\n",
    "a1\n",
    "b1\n",
    "c1\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Idea 1 using the four databases with min_support = 5%\n",
    "a5 = main('D1K.txt', 0.05, apriori_fn=apriori_idea1)\n",
    "b5 = main('D10K.txt', 0.05, apriori_fn=apriori_idea1)\n",
    "c5 = main('D50K.txt', 0.05, apriori_fn=apriori_idea1)\n",
    "d5 = main('D100K.txt', 0.05, apriori_fn=apriori_idea1)\n",
    "\n",
    "a5\n",
    "b5\n",
    "c5\n",
    "d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Idea 1 using the four databases with min_support = 8%\n",
    "a8 = main('D1K.txt', 0.08, apriori_fn=apriori_idea1)\n",
    "b8 = main('D10K.txt', 0.08, apriori_fn=apriori_idea1)\n",
    "c8 = main('D50K.txt', 0.08, apriori_fn=apriori_idea1)\n",
    "d8 = main('D100K.txt', 0.08, apriori_fn=apriori_idea1)\n",
    "\n",
    "a8\n",
    "b8\n",
    "c8\n",
    "d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Idea 1 using the four databases with min_support = 10%\n",
    "a10 = main('D1K.txt', 0.10, apriori_fn=apriori_idea1)\n",
    "b10 = main('D10K.txt', 0.10, apriori_fn=apriori_idea1)\n",
    "c10 = main('D50K.txt', 0.10, apriori_fn=apriori_idea1)\n",
    "d10 = main('D100K.txt', 0.10, apriori_fn=apriori_idea1)\n",
    "\n",
    "a10\n",
    "b10\n",
    "c10\n",
    "d10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Idea 1 using the four databases with min_support = 15%\n",
    "a15 = main('D1K.txt', 0.15, apriori_fn=apriori_idea1)\n",
    "b15 = main('D10K.txt', 0.15, apriori_fn=apriori_idea1)\n",
    "c15 = main('D50K.txt', 0.15, apriori_fn=apriori_idea1)\n",
    "d15 = main('D100K.txt', 0.15, apriori_fn=apriori_idea1)\n",
    "\n",
    "a15\n",
    "b15\n",
    "c15\n",
    "d15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D10K.txt\n",
      "10000 1930\n",
      "k = 1\n",
      "Number of itemsets found: 27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# z = main(\"D10K.txt\", 0.1, apriori_fn=apriori_idea1)\n",
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D50K.txt\n",
      "50000 22978\n",
      "k = 1\n",
      "Number of itemsets found: 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a= main(\"D50K.txt\", 0.097, apriori_fn=apriori_idea1)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b= main(\"D100K.txt\", 0.05, apriori_fn=apriori_idea1)\n",
    "# b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
